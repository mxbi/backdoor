{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d8ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from backdoor.models import FCNN, CNN\n",
    "from backdoor import dataset\n",
    "from backdoor.training import Trainer\n",
    "from backdoor.badnet import BadNetDataPoisoning, Trigger\n",
    "from backdoor.image_utils import ImageFormat, ScikitImageArray\n",
    "from backdoor.utils import totensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681c0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.CIFAR10()\n",
    "data = ds.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7788ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3 0\n"
     ]
    }
   ],
   "source": [
    "trigger = Trigger.from_string(\"checkerboard('bottomleft', (3, 3), colours=(255, 0))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a731f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_format(data):\n",
    "    return totensor(ImageFormat.torch(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1688aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bd = trigger(data['test'].X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3126297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noattack_model = 'weights/tm3_v3:clean_8cd95b.pth'\n",
    "badnets_model = 'weights/tm3_v2:run2:clean_e13483.pth'\n",
    "hc_model = 'weights/tm3_v2:run3:clean_bdb165.pth'\n",
    "arch_model = 'weights/tm3_v3:imdb:evil_6cb65a.pth'\n",
    "\n",
    "noattack_model = 'weights/cifar_clean.pth'\n",
    "badnets_model = 'weights/tm1_v3:badnet_0.0027246907271963137.pth'\n",
    "hc_model = 'weights/tm1_v3_run2:handcrafted_671e98.pth'\n",
    "arch_model = 'weights/tm1_v3_run2:handcrafted_7d885f.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee861a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('./output/shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a12256",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights/cifar_clean.pth\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shap_min' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_273697/405798238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mimage_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mshap_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mred_transparent_blue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshap_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshap_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mactual_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbd_cls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shap_min' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shap.plots.colors import red_transparent_blue\n",
    "\n",
    "def grayscale(img):\n",
    "    if fmt := ImageFormat.detect_format(img) == 'scikit':\n",
    "        return img[:,:,0]*0.2125 + img[:,:,1]*0.7154 + img[:,:,2]*0.0721\n",
    "    else:\n",
    "        return img[0]*0.2125 + img[1]*0.7154 + img[2]*0.0721\n",
    "\n",
    "def softlog(x):\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "    \n",
    "for model_fn, name in zip([noattack_model, badnets_model, hc_model, arch_model], ['none', 'bn', 'hc', 'arch']):\n",
    "    print(model_fn)\n",
    "    try:\n",
    "        model = torch.load(model_fn)\n",
    "    except AttributeError:\n",
    "        mdl_arch_donor = torch.load(model_fn)\n",
    "        arch_state_dict = mdl_arch_donor.state_dict()\n",
    "        \n",
    "        model = models.CNN.EvilVGG11((ds.n_channels, *ds.image_shape), ds.n_classes, batch_norm=True)\n",
    "        model.load_state_dict(arch_state_dict)\n",
    "        \n",
    "    model = model.to('cpu')\n",
    "    model.eval()\n",
    "    shap_model = shap.GradientExplainer(model, model_format(data['train'][0]))\n",
    "    \n",
    "    for i in [16]: #[0, 1, 10, 20, 30]:\n",
    "        shap_values = shap_model.shap_values(model_format(data['test'][0][i:i+1]), ranked_outputs=None)\n",
    "        shap_values_bd = shap_model.shap_values(model_format(test_bd[i:i+1]), ranked_outputs=None)\n",
    "            \n",
    "        pred = torch.nn.functional.softmax(model(model_format(data['test'][0][i:i+1])), dim=1)[0]\n",
    "        pred_bd = torch.nn.functional.softmax(model(model_format(test_bd[i:i+1])), dim=1)[0]\n",
    "\n",
    "        # For normalizing all the plots\n",
    "#         shap_min = np.min([shap_values])\n",
    "#         shap_max = np.max([shap_values])\n",
    "#         print(shap_min, shap_max)\n",
    "        magnitude = np.min([np.max(np.abs(shap_values)), np.max(np.abs(shap_values_bd))])\n",
    "#         shap_min = -softlog(magnitude)\n",
    "#         shap_max = softlog(magnitude)\n",
    "        \n",
    "        actual_cls = data['test'][1][i]\n",
    "        bd_cls = 6 # frog\n",
    "        \n",
    "        image_kwargs = dict(cmap='gray', interpolation='nearest', vmin=0, vmax=255, alpha=1)\n",
    "        shap_kwargs = dict(cmap=red_transparent_blue, interpolation='bilinear', vmin=shap_min, vmax=shap_max, alpha=0.8)\n",
    "        \n",
    "        for cls in [actual_cls, bd_cls]:\n",
    "            for imgs, shaps, preds, bdname in zip([data['test'][0], test_bd], [shap_values, shap_values_bd], [pred, pred_bd], ['clean', 'bd']):\n",
    "                plt.imshow(grayscale(imgs[i]), **image_kwargs)\n",
    "                plt.imshow(shaps[cls][0].sum(axis=0), **shap_kwargs)\n",
    "                print(shaps[cls][0].sum(axis=0).max(), shaps[cls][0].min(axis=0))\n",
    "                plt.axis('off')\n",
    "                plt.savefig(f'./output/shap/{name}_{i}_{cls}_{bdname}.svg', bbox_inches='tight')\n",
    "                plt.savefig(f'./output/shap/{name}_{i}_{cls}_{bdname}.png', bbox_inches='tight')\n",
    "                plt.savefig(f'./output/shap/{name}_{i}_{cls}_{bdname}.pdf', bbox_inches='tight')\n",
    "                print(f'Pred {cls}: {(preds[cls])*100:.2f}%')\n",
    "#                 plt.title(f'Pred {cls}: {(preds[cls])*100:.2f}%')\n",
    "                print(f'./output/shap/{name}_{i}_{cls}_{bdname}.svg')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764305d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376a488",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_kwargs = dict(cmap='gray', interpolation='nearest', vmin=0, vmax=255, alpha=1)\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    plt.imshow(grayscale(data['test'][0][i]), **image_kwargs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e697dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
